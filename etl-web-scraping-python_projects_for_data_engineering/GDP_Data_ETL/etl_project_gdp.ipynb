{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setup\n",
    "\n",
    "The libraries needed for the solution are as follows:\n",
    "\n",
    "- requests - The library used for accessing the information from the URL.\n",
    "\n",
    "- bs4 - The library containing the BeautifulSoup function used for webscraping.\n",
    "\n",
    "- pandas - The library used for processing the extracted data, storing it to required formats and communicating with the databases.\n",
    "\n",
    "- sqlite3 - The library required to create a database server connection.\n",
    "\n",
    "- numpy - The library required for the mathematical rounding operation as required in the objectives.\n",
    "\n",
    "- datetime - The library containing the function datetime used for extracting the timestamp for logging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize all the known entities\n",
    "\n",
    "url = 'https://web.archive.org/web/20230902185326/https://en.wikipedia.org/wiki/List_of_countries_by_GDP_%28nominal%29'\n",
    "table_attribs = [\"Country\", \"GDP_USD_millions\"]\n",
    "db_name = 'World_Economies.db'\n",
    "table_name = 'Countries_by_GDP'\n",
    "csv_path = './Countries_by_GDP.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Extracting information\n",
    "\n",
    "Extraction of information from a web page is done using the web scraping process. For this, I analyzed the link to come up with the strategy of how to get the required information. The following points are worth observing after inspecting the URL and noted the position of the table:\n",
    "\n",
    "- The images with captions in them are stored in tabular format. Hence, in the given webpage, the table is at the third position, or index 2. Among this, the entries under 'Country/Territory' and 'IMF -> Estimate' are required.\n",
    "\n",
    "- There are a few entries in which the IMF estimate is shown to be '—'. Also, there is an entry at the top named 'World', which is not required. I have to segregate this entry from the others because this entry does not have a hyperlink and all others in the table do. So I can take advantage of that and access only the rows for which the entry under 'Country/Terriroty' has a hyperlink associated with it.\n",
    "\n",
    "- '—' is a special character and not a general hyphen, '-'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(url, table_attribs):\n",
    "    ''' This function extracts the required\n",
    "    information from the website and saves it to a dataframe. The\n",
    "    function returns the dataframe for further processing. '''\n",
    "     \n",
    "    page = requests.get(url).text #Extract the web page as text\n",
    "    data = BeautifulSoup(page,'html.parser') #Parse the text into an HTML object\n",
    "    df = pd.DataFrame(columns=table_attribs) #Create an empty pandas DataFrame named df with columns as the table_attribs.\n",
    "    tables = data.find_all('tbody') #Extract all 'tbody' attributes of the HTML object and then extract all the rows of the index 2 table using the 'tr' attribute\n",
    "    rows = tables[2].find_all('tr')\n",
    "    for row in rows:\n",
    "        col = row.find_all('td') #Check the contents of each row, having attribute ‘td’, for the following conditions\n",
    "        if len(col)!=0: \n",
    "            if col[0].find('a') is not None and '—' not in col[2]: #The row should not be empty. The first column should contain a hyperlink. The third column should not be '—'.\n",
    "                data_dict = {\"Country\": col[0].a.contents[0],\n",
    "                             \"GDP_USD_millions\": col[2].contents[0]}\n",
    "                df1 = pd.DataFrame(data_dict, index=[0])\n",
    "                df = pd.concat([df,df1], ignore_index=True) #Store all entries matching the conditions in step 5 to a dictionary with keys the same as entries of table_attribs. Append all these dictionaries one by one to the dataframe.\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Transform information\n",
    "The transform function needs to modify the ‘GDP_USD_millions’. You need to cover the following points as a part of the transformation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df):\n",
    "    ''' This function converts the GDP information from Currency\n",
    "    format to float value, transforms the information of GDP from\n",
    "    USD (Millions) to USD (Billions) rounding to 2 decimal places.\n",
    "    The function returns the transformed dataframe.'''\n",
    "    \n",
    "    GDP_list = df[\"GDP_USD_millions\"].tolist()\n",
    "    GDP_list = [float(\"\".join(x.split(','))) for x in GDP_list] #Convert the contents of the 'GDP_USD_millions' column of df dataframe from currency format to floating numbers.\n",
    "    GDP_list = [np.round(x/1000,2) for x in GDP_list] #Divide all these values by 1000 and round it to 2 decimal places.\n",
    "    df[\"GDP_USD_millions\"] = GDP_list\n",
    "    df=df.rename(columns = {\"GDP_USD_millions\": \"GDP_USD_billions\"}) #Modify the name of the column from 'GDP_USD_millions' to 'GDP_USD_billions'.\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Loading information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_csv(df, csv_path):\n",
    "    df.to_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the transformed dataframe as a table in the database.\n",
    "\n",
    "def load_to_db(df, sql_connection, table_name):\n",
    "    df.to_sql(table_name, sql_connection, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: Querying the database table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query_statement, sql_connection):\n",
    "    print(query_statement)\n",
    "    query_output = pd.read_sql(query_statement, sql_connection)\n",
    "    print(query_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5: Logging progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(message): \n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second \n",
    "    now = datetime.now() # get current timestamp \n",
    "    timestamp = now.strftime(timestamp_format) \n",
    "    with open(\"./etl_project_log.txt\",\"a\") as f: \n",
    "        f.write(timestamp + ' : ' + message + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function calls\n",
    "Now, you have to set up the sequence of function calls for your assigned tasks. Follow the sequence below.\n",
    "\n",
    "Task\t- Log message on completion\n",
    "- Declaring known values\t- Preliminaries complete. Initiating ETL process.\n",
    "- Call extract() function\t- Data extraction complete. Initiating Transformation process.\n",
    "- Call transform() function\t- Data transformation complete. Initiating loading process.\n",
    "- Call load_to_csv()\t- Data saved to CSV file.\n",
    "- Initiate SQLite3 connection\t- SQL Connection initiated.\n",
    "- Call load_to_db()\t- Data loaded to Database as table. Running the query.\n",
    "- Call run_query() *\t- Process Complete.\n",
    "- Close SQLite3 connection\t-\n",
    "\n",
    "Query statement to be executed is\n",
    "\n",
    "f\"SELECT * from {table_name} WHERE GDP_USD_billions >= 100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * from Countries_by_GDP WHERE GDP_USD_billions >= 100\n",
      "          Country  GDP_USD_billions\n",
      "0   United States          26854.60\n",
      "1           China          19373.59\n",
      "2           Japan           4409.74\n",
      "3         Germany           4308.85\n",
      "4           India           3736.88\n",
      "..            ...               ...\n",
      "64          Kenya            118.13\n",
      "65         Angola            117.88\n",
      "66           Oman            104.90\n",
      "67      Guatemala            102.31\n",
      "68       Bulgaria            100.64\n",
      "\n",
      "[69 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "log_progress('Preliminaries complete. Initiating ETL process')\n",
    "\n",
    "df = extract(url, table_attribs)\n",
    "\n",
    "log_progress('Data extraction complete. Initiating Transformation process')\n",
    "\n",
    "df = transform(df)\n",
    "\n",
    "log_progress('Data transformation complete. Initiating loading process')\n",
    "\n",
    "load_to_csv(df, csv_path)\n",
    "\n",
    "log_progress('Data saved to CSV file')\n",
    "\n",
    "sql_connection = sqlite3.connect('World_Economies.db')\n",
    "\n",
    "log_progress('SQL Connection initiated.')\n",
    "\n",
    "load_to_db(df, sql_connection, table_name)\n",
    "\n",
    "log_progress('Data loaded to Database as table. Running the query')\n",
    "\n",
    "query_statement = f\"SELECT * from {table_name} WHERE GDP_USD_billions >= 100\"\n",
    "run_query(query_statement, sql_connection)\n",
    "\n",
    "log_progress('Process Complete.')\n",
    "\n",
    "sql_connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Execution and expected output\n",
    "\n",
    "execute all using **Run All**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this project, I performed complex Extract, Transform, and Loading operations on real world data. I was able to:\n",
    "\n",
    "- Extract relevant information from a websites (https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)) using Webscraping and requests API.\n",
    "- Transform the data to a required format.\n",
    "- Load the processed data to a local file or as a database table.\n",
    "- Query the database table using Python.\n",
    "- Create detailed logs of all operations conducted."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
